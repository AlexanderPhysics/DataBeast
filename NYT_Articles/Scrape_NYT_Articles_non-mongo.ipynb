{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests,json, time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.listchallenges.com/f/lists/d7aacdae-74bd-42ff-b397-b73905b5867b.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Our goal is to scape as many New York Times articles from their api as possible. The web scraper below is desgined to open a mongo client, where all the downloaded articles will be stored and make api calls. This web scraper will run indefinately until the user termintes the code's calls. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New York Times API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def call_api(url, payload, p=0):\n",
    "    # Add the 'page' parameter to the payload.\n",
    "    payload['page'] = p\n",
    "\n",
    "    # Get the requested url. Error handling for bad requests should be done in\n",
    "    # the calling function.\n",
    "    return requests.get(url, params=payload)\n",
    "\n",
    "\n",
    "def get_response(r):\n",
    "    # Use json.loads to read the response text\n",
    "    raw = json.loads(r.text)\n",
    "\n",
    "    # Return the meta (hits, etc.) and docs (containing urls'n'stuff) back\n",
    "    return raw['response']['meta'], raw['response']['docs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Url for NYT dev api\n",
    "NYT_URL = 'http://api.nytimes.com/svc/search/v2/articlesearch.json'\n",
    "api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Request all of the newest articles matching the search term\n",
    "payload  = {'sort': 'newest',\n",
    "            'api-key': api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [1,2,3,4,5]\n",
    "docs_list = []\n",
    "for page in pages:\n",
    "# Call the API with BaseURL + params and page\n",
    "    r = call_api(NYT_URL, payload, page)\n",
    "    meta, docs = get_response(r)\n",
    "    docs_list.append(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
