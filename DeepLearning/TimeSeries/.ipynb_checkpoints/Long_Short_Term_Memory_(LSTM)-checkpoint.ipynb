{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short Term Memory (LSTM) - Overcoming limitations of RNN\n",
    "\n",
    "\n",
    "### Readings\n",
    "\n",
    "http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf - Hochreiter's original paper on LSTM\n",
    "\n",
    "http://arxiv.org/pdf/1410.4615.pdf - Sutskever SOTA LSTM - Feb 2015\n",
    "\n",
    "http://arxiv.org/pdf/1506.00019v4.pdf - Lipton's excellent survey of RNN\n",
    "\n",
    "https://www.youtube.com/watch?v=izGl1YSH_JA - Hinton video on LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM background\n",
    "\n",
    "http://arxiv.org/pdf/1506.00019v4.pdf - architecture of LSTM\n",
    "\n",
    "https://www.youtube.com/watch?v=izGl1YSH_JA - Hinton video gives clear animation of signal coming into LSTM, waiting in LSTM until useful, gradient calculation and signal leaving LSTM.  Anyone bring popcorn?\n",
    "\n",
    "LSTM was invented by Hochreiter to overcome some of the issues with conventional RNN's.  The forget gate was introduced by Gers et. al.  Code for LSTM is below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#based on  code from https://gist.github.com/tmramalho/5e8fda10f99233b2370f\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import cPickle as pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import izip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "\n",
    "    def __init__(self, nin, n_hidden, nout):\n",
    "        rng = np.random.RandomState(1234)\n",
    "        # cell input\n",
    "        W_ug = np.asarray(rng.normal(size=(nin, n_hidden), scale= .01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        W_hg = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale=.01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        b_g = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # input gate equation\n",
    "        W_ui = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hi = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_i = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # forget gate equations\n",
    "        W_uf = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hf = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_f = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # cell output gate equations\n",
    "        W_uo = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_ho = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_o = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # output layer\n",
    "        W_hy = np.asarray(rng.normal(size=(n_hidden, nout), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_hy = np.zeros((nout,), dtype=theano.config.floatX)\n",
    "\n",
    "        # cell input\n",
    "        W_ug = theano.shared(W_ug, 'W_ug')\n",
    "        W_hg = theano.shared(W_hg, 'W_hg')\n",
    "        b_g = theano.shared(b_g, 'b_g')\n",
    "        # input gate equation\n",
    "        W_ui = theano.shared(W_ui, 'W_ui')\n",
    "        W_hi = theano.shared(W_hi, 'W_hi')\n",
    "        b_i = theano.shared(b_i, 'b_i')\n",
    "        # forget gate equations\n",
    "        W_uf = theano.shared(W_uf, 'W_uf')\n",
    "        W_hf = theano.shared(W_hf, 'W_hf')\n",
    "        b_f = theano.shared(b_f, 'b_f')\n",
    "        # cell output gate equations\n",
    "        W_uo = theano.shared(W_uo, 'W_uo')\n",
    "        W_ho = theano.shared(W_ho, 'W_ho')\n",
    "        b_o = theano.shared(b_o, 'b_o')\n",
    "        # output layer\n",
    "        W_hy = theano.shared(W_hy, 'W_hy')\n",
    "        b_hy = theano.shared(b_hy, 'b_hy')\n",
    "\n",
    "        self.activ1 = T.nnet.sigmoid\n",
    "        self.activ2 = T.tanh\n",
    "        \n",
    "        lr = T.scalar()\n",
    "        u = T.matrix()\n",
    "        t = T.scalar()\n",
    "\n",
    "\n",
    "        h0_tm1 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "        s0_tm1 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "\n",
    "\n",
    "        #theano.printing.debugprint([h0_tm1, u, W_hh, W_uh, W_hy, b_hh, b_hy], print_type=True)\n",
    "        [h, s], _ = theano.scan(self.recurrent_fn, sequences = u,\n",
    "                           outputs_info = [h0_tm1, s0_tm1],\n",
    "                           non_sequences = [W_ug, W_hg, b_g, W_ui, W_hi,\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy])\n",
    "\n",
    "        y = T.dot(h[-1], W_hy) + b_hy\n",
    "        cost = ((t - y)**2).mean(axis=0).sum()\n",
    "\n",
    "        gW_ug, gW_hg, gb_g, gW_ui, gW_hi, gb_i, \\\n",
    "        gW_uf, gW_hf, gb_f, gW_uo, gW_ho, gb_o, gW_hy, gb_hy \\\n",
    "            = T.grad(cost, [W_ug, W_hg, b_g, W_ui, W_hi, b_i, \\\n",
    "            W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy])\n",
    "            \n",
    "        update = [(W_ug, W_ug - lr*gW_ug), \n",
    "                  (W_hg, W_hg - lr*gW_hg ), \n",
    "                  (b_g, b_g - lr*gb_g), \n",
    "                  (W_ui, W_ui - lr*gW_ui),\n",
    "                  (W_hi, W_hi - lr*gW_hi), \n",
    "                  (b_i, b_i - lr*gb_i), \n",
    "                  (W_uf, W_uf - lr*gW_uf), \n",
    "                  (W_hf, W_hf - lr*gW_hf),\n",
    "                  (b_f, b_f - lr*gb_f),\n",
    "                  (W_uo, W_uo - lr*gW_uo), \n",
    "                  (W_ho, W_ho - lr*gW_ho), \n",
    "                  (b_o, b_o - lr*gb_o),\n",
    "                  (W_hy, W_hy - lr*gW_hy), \n",
    "                  (b_hy, b_hy - lr*gb_hy)]\n",
    "        \n",
    "        #theano.printing.debugprint([h0_tm1], print_type=True)\n",
    "        self.train_step = theano.function([u, t, lr], cost,\n",
    "            on_unused_input='warn',\n",
    "            updates=update,\n",
    "            allow_input_downcast=True)\n",
    "        \n",
    "        \n",
    "                \n",
    "        self.predict_step = theano.function([u, t], cost,\n",
    "           on_unused_input='warn',\n",
    "           allow_input_downcast=True)\n",
    "        \n",
    "\n",
    "    def recurrent_fn(self, u_t, h_tm1, s_tm1, W_ug, W_hg, b_g, W_ui, W_hi,\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy):\n",
    "        g_t = self.activ2(T.dot(u_t, W_ug) + T.dot(h_tm1, W_hg) + b_g)\n",
    "        i_t = self.activ1(T.dot(u_t, W_ui) + T.dot(h_tm1, W_hi) + b_i)\n",
    "        f_t = self.activ1(T.dot(u_t, W_uf) + T.dot(h_tm1, W_hf) + b_f)\n",
    "        o_t = self.activ1(T.dot(u_t, W_uo) + T.dot(h_tm1, W_ho) + b_o)\n",
    "        s_t = g_t * i_t + s_tm1*f_t\n",
    "        h_t = self.activ2(s_t)*o_t\n",
    "        \n",
    "        #h_t = self.activ2(T.dot(h_tm1, W_hh) + T.dot(u_t, W_uh) + b_hh)\n",
    "        return [h_t, s_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(xlist, ylist) = pickle.load(open('stockTT.bin', 'rb'))\n",
    "nInputs = len(xlist[0])\n",
    "x = np.array(xlist, dtype = theano.config.floatX)\n",
    "y = np.array(ylist, dtype = theano.config.floatX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nHidden = 20\n",
    "nOutputs = 1\n",
    "rnn = RNN(nInputs, nHidden, nOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "e = 1.0\n",
    "nPasses = 1\n",
    "vals = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iteration 0: 0.870665775953\n",
      "train iteration 200: 0.122261982784\n",
      "train iteration 400: 2.9393555349\n",
      "train iteration 600: 3.04606071309\n",
      "train iteration 800: 2.99885092753\n",
      "train iteration 1000: 0.256862316415\n",
      "train iteration 1200: 0.918914829659\n",
      "train iteration 1400: 0.772946626322\n",
      "train iteration 1600: 0.616126532697\n",
      "train iteration 1800: 0.200537697382\n",
      "train iteration 2000: 0.212814463965\n",
      "train iteration 2200: 1.22106003581\n",
      "train iteration 2400: 0.552616622684\n",
      "train iteration 2600: 0.551956887433\n",
      "test iteration 44: 1.27406577595\n",
      "test iteration 244: 0.832834224047\n",
      "test iteration 444: 4.07993422405\n",
      "test iteration 644: 1.51633422405\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "train_length = int(len(x) * 0.8)\n",
    "test_length = len(x) - train_length\n",
    "for i in range(nPasses):\n",
    "    # train weights\n",
    "    for j in xrange(train_length):\n",
    "        u = np.asarray(xlist[j], dtype = theano.config.floatX).reshape((1,nInputs))\n",
    "        t = y[j]\n",
    "        \n",
    "        c = rnn.train_step(u, t, lr)\n",
    "        if j%200==0: print \"train iteration {0}: {1}\".format(j, np.sqrt(c))\n",
    "        e = 0.1*np.sqrt(c) + 0.9*e\n",
    "        # for taining modification, do not smooth the error\n",
    "        train_mse.append(np.sqrt(c))\n",
    "                   \n",
    "    # make predictions                       \n",
    "    for k in xrange(train_length,len(x)):\n",
    "        u = np.asarray(xlist[k], dtype = theano.config.floatX).reshape((1,nInputs))\n",
    "        t = y[k]\n",
    "\n",
    "        c = rnn.predict_step(u, t)\n",
    "        if k%200==0: print \"test iteration {0}: {1}\".format(k - train_length, np.sqrt(c))\n",
    "        #e = 0.1*np.sqrt(c) + 0.9*e\n",
    "        # for taining modification, do not smooth the error\n",
    "        test_mse.append(np.sqrt(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error 1.24968266264\n",
      "test error 1.43396332708\n"
     ]
    }
   ],
   "source": [
    "print \"train error {}\".format(np.mean(train_mse))\n",
    "print \"test error {}\".format(np.mean(test_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzkAAAFwCAYAAACb2rWUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e63f750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (14,6))\n",
    "plt.plot(test_mse, label = \"test error\")\n",
    "plt.plot(train_mse, label = \"train error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q's\n",
    "1.  Make parametric changes to LSTM and see how performance changes. \n",
    "2.  Add \"peephole\" connection mentioned in Lipton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Make parametric changes to LSTM and see how performance changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nHidden = 20 # increase number of hidden nodes 20 --> 100\n",
    "nOutputs = 1\n",
    "rnn = RNN(nInputs, nHidden, nOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "e = 1.0\n",
    "nPasses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iteration 0: 1.27395111455\n",
      "train iteration 200: 4.64426812733\n",
      "train iteration 400: 4.87307903011\n",
      "train iteration 600: 1.48564697427\n",
      "train iteration 800: 3.33310481091\n",
      "train iteration 1000: 0.524721442891\n",
      "train iteration 1200: 0.602715636987\n",
      "train iteration 1400: 0.645676918676\n",
      "train iteration 1600: 1.19555392539\n",
      "train iteration 1800: 0.621014439222\n",
      "train iteration 2000: 2.16546465862\n",
      "train iteration 2200: 0.828576175891\n",
      "train iteration 2400: 0.996606788177\n",
      "train iteration 2600: 0.279571467713\n",
      "test iteration 44: 1.49264952847\n",
      "test iteration 244: 0.614250471525\n",
      "test iteration 444: 3.86135047153\n",
      "test iteration 644: 1.29775047153\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "train_mse_h = []\n",
    "test_mse_h = []\n",
    "train_length = int(len(x) * 0.8)\n",
    "test_length = len(x) - train_length\n",
    "for i in range(nPasses):\n",
    "    # train weights\n",
    "    for j in xrange(train_length):\n",
    "        u = np.asarray(xlist[j], dtype = theano.config.floatX).reshape((1,nInputs))\n",
    "        t = y[j]\n",
    "        \n",
    "        c = rnn.train_step(u, t, lr)\n",
    "        if j%200==0: print \"train iteration {0}: {1}\".format(j, np.sqrt(c))\n",
    "        #e = 0.1*np.sqrt(c) + 0.9*e\n",
    "        # for taining modification, do not smooth the error\n",
    "        train_mse_h.append(np.sqrt(c))\n",
    "                   \n",
    "    # make predictions                       \n",
    "    for k in xrange(train_length,len(x)):\n",
    "        u = np.asarray(xlist[k], dtype = theano.config.floatX).reshape((1,nInputs))\n",
    "        t = y[k]\n",
    "\n",
    "        c = rnn.predict_step(u, t)\n",
    "        if k%200==0: print \"test iteration {0}: {1}\".format(k - train_length, np.sqrt(c))\n",
    "        #e = 0.1*np.sqrt(c) + 0.9*e\n",
    "        # for taining modification, do not smooth the error\n",
    "        test_mse_h.append(np.sqrt(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train error 1.75193876893\n",
      "test error 1.42273464588\n"
     ]
    }
   ],
   "source": [
    "print \"train error {}\".format(np.mean(train_mse_h))\n",
    "print \"test error {}\".format(np.mean(test_mse_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn nest the parameter matricies into a list, each index representing a different cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "\n",
    "    def __init__(self, nin, n_hidden, nout):\n",
    "        \n",
    "        # Initalize Parameters for 1st cell\n",
    "        rng = np.random.RandomState(1234)\n",
    "        # cell input\n",
    "        W_ug = np.asarray(rng.normal(size=(nin, n_hidden), scale= .01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        W_hg = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale=.01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        b_g = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # input gate equation\n",
    "        W_ui = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hi = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_i = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # forget gate equations\n",
    "        W_uf = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hf = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_f = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # cell output gate equations\n",
    "        W_uo = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_ho = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_o = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # output layer\n",
    "        #W_hy = np.asarray(rng.normal(size=(n_hidden, nout), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        #b_hy = np.zeros((nout,), dtype=theano.config.floatX)\n",
    "        \n",
    "        # Initalize Parameters for 2st cell\n",
    "        rng = np.random.RandomState(6673)\n",
    "        # cell input\n",
    "        W_ug_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale= .01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        W_hg_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale=.01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        b_g_2 = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # input gate equation\n",
    "        W_ui_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hi_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_i_2 = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # forget gate equations\n",
    "        W_uf_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hf_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_f_2 = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # cell output gate equations\n",
    "        W_uo_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_ho_2 = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_o_2 = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # output layer\n",
    "        W_hy_2 = np.asarray(rng.normal(size=(n_hidden, nout), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_hy_2 = np.zeros((nout,), dtype=theano.config.floatX)        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # Parameters for 1st cell\n",
    "        # cell input\n",
    "        W_ug = theano.shared(W_ug, 'W_ug')\n",
    "        W_hg = theano.shared(W_hg, 'W_hg')\n",
    "        b_g = theano.shared(b_g, 'b_g')\n",
    "        # input gate equation\n",
    "        W_ui = theano.shared(W_ui, 'W_ui')\n",
    "        W_hi = theano.shared(W_hi, 'W_hi')\n",
    "        b_i = theano.shared(b_i, 'b_i')\n",
    "        # forget gate equations\n",
    "        W_uf = theano.shared(W_uf, 'W_uf')\n",
    "        W_hf = theano.shared(W_hf, 'W_hf')\n",
    "        b_f = theano.shared(b_f, 'b_f')\n",
    "        # cell output gate equations\n",
    "        W_uo = theano.shared(W_uo, 'W_uo')\n",
    "        W_ho = theano.shared(W_ho, 'W_ho')\n",
    "        b_o = theano.shared(b_o, 'b_o')\n",
    "        # output layer\n",
    "        #W_hy = theano.shared(W_hy, 'W_hy')\n",
    "        #b_hy = theano.shared(b_hy, 'b_hy')\n",
    "        \n",
    "        \n",
    "        # Parameters for 2st cell\n",
    "        # cell input\n",
    "        W_ug_2 = theano.shared(W_ug_2, 'W_ug_2')\n",
    "        W_hg_2 = theano.shared(W_hg_2, 'W_hg_2')\n",
    "        b_g_2 = theano.shared(b_g_2, 'b_g_2')\n",
    "        # input gate equation\n",
    "        W_ui_2 = theano.shared(W_ui_2, 'W_ui_2')\n",
    "        W_hi_2 = theano.shared(W_hi_2, 'W_hi_2')\n",
    "        b_i_2 = theano.shared(b_i_2, 'b_i_2')\n",
    "        # forget gate equations\n",
    "        W_uf_2 = theano.shared(W_uf_2, 'W_uf_2')\n",
    "        W_hf_2 = theano.shared(W_hf_2, 'W_hf_2')\n",
    "        b_f_2 = theano.shared(b_f_2, 'b_f_2')\n",
    "        # cell output gate equations\n",
    "        W_uo_2 = theano.shared(W_uo_2, 'W_uo_2')\n",
    "        W_ho_2 = theano.shared(W_ho_2, 'W_ho_2')\n",
    "        b_o_2 = theano.shared(b_o_2, 'b_o_2')\n",
    "        # output layer\n",
    "        W_hy_2 = theano.shared(W_hy_2, 'W_hy_2')\n",
    "        b_hy_2 = theano.shared(b_hy_2, 'b_hy_2')        \n",
    "        \n",
    "\n",
    "\n",
    "        self.activ1 = T.nnet.sigmoid\n",
    "        self.activ2 = T.tanh\n",
    "        \n",
    "        lr = T.scalar()\n",
    "        u = T.matrix()\n",
    "        t = T.scalar()\n",
    "\n",
    "\n",
    "        h0_tm1 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "        s0_tm1 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "        h_tm1_2 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "        s_tm1_2 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "\n",
    "\n",
    "        #theano.printing.debugprint([h0_tm1, u, W_hh, W_uh, W_hy, b_hh, b_hy], print_type=True)\n",
    "        [ h,s,h1,s1],_ = theano.scan(self.recurrent_fn, sequences = u,\n",
    "                           outputs_info = [h0_tm1, s0_tm1,h_tm1_2, s_tm1_2], \n",
    "                           non_sequences = [W_ug, W_hg, b_g, W_ui, W_hi,\\\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, \\\n",
    "                                            W_ho, b_o,\\\n",
    "                                            W_ug_2, W_hg_2, b_g_2, W_ui_2, W_hi_2,\\\n",
    "                                            b_i_2, W_uf_2, W_hf_2, b_f_2, W_uo_2, \\\n",
    "                                            W_ho_2, b_o_2, W_hy_2, b_hy_2])\n",
    "\n",
    "        y = T.dot(h[-1], W_hy_2) + b_hy_2\n",
    "        cost = ((t - y)**2).mean(axis=0).sum()\n",
    "\n",
    "        gW_ug, gW_hg, gb_g, gW_ui, gW_hi, gb_i, \\\n",
    "        gW_uf, gW_hf, gb_f, gW_uo, gW_ho, gb_o, \\\n",
    "        gW_ug_2, gW_hg_2, gb_g_2, gW_ui_2, gW_hi_2, gb_i_2, \\\n",
    "        gW_uf_2, gW_hf_2, gb_f_2, gW_uo_2, gW_ho_2, gb_o_2, \\\n",
    "        gW_hy_2, gb_hy_2 \\\n",
    "            = T.grad(cost, [W_ug, W_hg, b_g, W_ui, W_hi, b_i, \\\n",
    "                            W_uf, W_hf, b_f, W_uo, W_ho, b_o,\\\n",
    "                           W_ug_2, W_hg_2, b_g_2, W_ui_2, W_hi_2, b_i_2, \\\n",
    "                            W_uf_2, W_hf_2, b_f_2, W_uo_2, W_ho_2, b_o_2, W_hy_2, b_hy_2])\n",
    "            \n",
    "        update = [(W_ug, W_ug - lr*gW_ug), \n",
    "                  (W_hg, W_hg - lr*gW_hg ), \n",
    "                  (b_g, b_g - lr*gb_g), \n",
    "                  (W_ui, W_ui - lr*gW_ui),\n",
    "                  (W_hi, W_hi - lr*gW_hi), \n",
    "                  (b_i, b_i - lr*gb_i), \n",
    "                  (W_uf, W_uf - lr*gW_uf), \n",
    "                  (W_hf, W_hf - lr*gW_hf),\n",
    "                  (b_f, b_f - lr*gb_f), \n",
    "                  (W_uo, W_uo - lr*gW_uo), \n",
    "                  (W_ho, W_ho - lr*gW_ho), \n",
    "                  (b_o, b_o - lr*gb_o),\n",
    "                  #(W_hy, W_hy - lr*gW_hy), \n",
    "                  #(b_hy, b_hy - lr*gb_hy),\n",
    "                 \n",
    "                 (W_ug_2, W_ug_2 - lr*gW_ug_2), \n",
    "                  (W_hg_2, W_hg_2 - lr*gW_hg_2 ), \n",
    "                  (b_g_2, b_g_2 - lr*gb_g_2), \n",
    "                  (W_ui_2, W_ui_2 - lr*gW_ui_2),\n",
    "                  (W_hi_2, W_hi_2 - lr*gW_hi_2), \n",
    "                  (b_i_2, b_i_2 - lr*gb_i_2), \n",
    "                  (W_uf_2, W_uf_2 - lr*gW_uf_2), \n",
    "                  (W_hf_2, W_hf_2 - lr*gW_hf_2),\n",
    "                  (b_f_2, b_f_2 - lr*gb_f_2), \n",
    "                  (W_uo_2, W_uo_2 - lr*gW_uo_2), \n",
    "                  (W_ho_2, W_ho_2 - lr*gW_ho_2), \n",
    "                  (b_o_2, b_o_2 - lr*gb_o_2),\n",
    "                  (W_hy_2, W_hy_2 - lr*gW_hy_2), \n",
    "                  (b_hy_2, b_hy_2 - lr*gb_hy_2)\n",
    "                 ]\n",
    "        \n",
    "        #theano.printing.debugprint([h0_tm1], print_type=True)\n",
    "        \n",
    "        # Train\n",
    "        self.train_step = theano.function([u, t, lr], cost,\n",
    "            on_unused_input='warn',\n",
    "            updates=update,\n",
    "            allow_input_downcast=True)\n",
    "        \n",
    "        \n",
    "        # Predict      \n",
    "        self.predict_step = theano.function([u, t], cost,\n",
    "           on_unused_input='warn',\n",
    "           allow_input_downcast=True)\n",
    "        \n",
    "\n",
    "    def recurrent_fn(self, u_t, h_tm1, s_tm1, h_tm1_2, s_tm1_2,W_ug, W_hg, b_g, W_ui, W_hi,\n",
    "                           b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, \n",
    "                     \n",
    "                                 W_ug_2, W_hg_2, b_g_2, W_ui_2, W_hi_2,\n",
    "                           b_i_2, W_uf_2, W_hf_2, b_f_2, W_uo_2, W_ho_2, b_o_2, W_hy_2, b_hy_2):\n",
    "\n",
    "        # 1st cell \n",
    "        g_t = self.activ2(T.dot(u_t, W_ug) + T.dot(h_tm1, W_hg) + b_g)\n",
    "        i_t = self.activ1(T.dot(u_t, W_ui) + T.dot(h_tm1, W_hi) + b_i)\n",
    "        f_t = self.activ1(T.dot(u_t, W_uf) + T.dot(h_tm1, W_hf) + b_f)\n",
    "        o_t = self.activ1(T.dot(u_t, W_uo) + T.dot(h_tm1, W_ho) + b_o)\n",
    "        s_t = g_t * i_t + s_tm1*f_t\n",
    "        h_t = self.activ2(s_t)*o_t\n",
    "        \n",
    "        \n",
    "        # 2nd cell\n",
    "        # ouput of 1st cell, h_t, is the input of the 2nd cell\n",
    "        g_t_2 = self.activ2(T.dot(h_t, W_ug_2) + T.dot(h_tm1_2, W_hg_2) + b_g_2)\n",
    "        i_t_2 = self.activ1(T.dot(h_t, W_ui_2) + T.dot(h_tm1_2, W_hi_2) + b_i_2)\n",
    "        f_t_2 = self.activ1(T.dot(h_t, W_uf_2) + T.dot(h_tm1_2, W_hf_2) + b_f_2)\n",
    "        o_t_2 = self.activ1(T.dot(h_t, W_uo_2) + T.dot(h_tm1_2, W_ho_2) + b_o_2)\n",
    "        s_t_2 = g_t_2 * i_t_2 + s_tm1_2*f_t_2\n",
    "        h_t_2 = self.activ2(s_t_2)*o_t_2\n",
    "        \n",
    "        #h_t = self.activ(T.dot(h_tm1, W_hh) + T.dot(u_t, W_uh) + b_hh)\n",
    "        return [h_t_2,s_t_2,h_t,s_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nHidden = 20\n",
    "nOutputs = 1\n",
    "rnn = RNN(nInputs, nHidden, nOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run model\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "train_length = int(len(x) * 0.8)\n",
    "test_length = len(x) - train_length\n",
    "lr = 1e-1\n",
    "e = 1.0\n",
    "nPasses = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iteration 0: 1.27996425235\n",
      "train iteration 200: 4.24800313233\n",
      "train iteration 400: 5.08333125116\n",
      "train iteration 600: 1.77125189481\n",
      "train iteration 800: 3.42133843836\n",
      "train iteration 1000: 0.325689251337\n",
      "train iteration 1200: 0.859534416952\n",
      "train iteration 1400: 0.772966004118\n",
      "train iteration 1600: 1.2439123503\n",
      "train iteration 1800: 0.560396685469\n",
      "train iteration 2000: 1.99870700687\n",
      "train iteration 2200: 0.862844691794\n",
      "train iteration 2400: 1.24175198779\n",
      "train iteration 2600: 0.444249814864\n",
      "test iteration 44: 1.29207126239\n",
      "test iteration 244: 0.814828737607\n",
      "test iteration 444: 4.06192873761\n",
      "test iteration 644: 1.49832873761\n"
     ]
    }
   ],
   "source": [
    "# run model\n",
    "for i in range(nPasses):\n",
    "    # train weights\n",
    "    for j in xrange(train_length):\n",
    "        u = np.asarray(xlist[j], dtype = theano.config.floatX).reshape((1,nInputs))\n",
    "        t = y[j]\n",
    "        \n",
    "        c = rnn.train_step(u, t, lr)\n",
    "        if j%200==0: print \"train iteration {0}: {1}\".format(j, np.sqrt(c))\n",
    "        e = 0.1*np.sqrt(c) + 0.9*e\n",
    "        # for taining modification, do not smooth the error\n",
    "        train_mse.append(np.sqrt(c))\n",
    "                   \n",
    "    # make predictions                       \n",
    "    for k in xrange(train_length,len(x)):\n",
    "        u = np.asarray(xlist[k], dtype = theano.config.floatX).reshape((1,nInputs))\n",
    "        t = y[k]\n",
    "\n",
    "        c = rnn.predict_step(u, t)\n",
    "        if k%200==0: print \"test iteration {0}: {1}\".format(k - train_length, np.sqrt(c))\n",
    "        #e = 0.1*np.sqrt(c) + 0.9*e\n",
    "        # for taining modification, do not smooth the error\n",
    "        test_mse.append(np.sqrt(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change LSMT for Character Prediction\n",
    "\n",
    "### How to change the above code in order to incorporate the LSTM model\n",
    "    1. change dim output layer\n",
    "    2. change output layer act func to softmax for classification\n",
    "    3. change loss to cross-entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "\n",
    "    def __init__(self, nin, n_hidden, nout):\n",
    "        rng = np.random.RandomState(1234)\n",
    "        # cell input\n",
    "        W_ug = np.asarray(rng.normal(size=(nin, n_hidden), scale= .01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        W_hg = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale=.01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        b_g = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # input gate equation\n",
    "        W_ui = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hi = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_i = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # forget gate equations\n",
    "        W_uf = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hf = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_f = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # cell output gate equations\n",
    "        W_uo = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_ho = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_o = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # output layer\n",
    "        W_hy = np.asarray(rng.normal(size=(n_hidden,nout), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_hy = np.zeros((nout,), dtype=theano.config.floatX)\n",
    "\n",
    "        # cell input\n",
    "        W_ug = theano.shared(W_ug, 'W_ug')\n",
    "        W_hg = theano.shared(W_hg, 'W_hg')\n",
    "        b_g = theano.shared(b_g, 'b_g')\n",
    "        # input gate equation\n",
    "        W_ui = theano.shared(W_ui, 'W_ui')\n",
    "        W_hi = theano.shared(W_hi, 'W_hi')\n",
    "        b_i = theano.shared(b_i, 'b_i')\n",
    "        # forget gate equations\n",
    "        W_uf = theano.shared(W_uf, 'W_uf')\n",
    "        W_hf = theano.shared(W_hf, 'W_hf')\n",
    "        b_f = theano.shared(b_f, 'b_f')\n",
    "        # cell output gate equations\n",
    "        W_uo = theano.shared(W_uo, 'W_uo')\n",
    "        W_ho = theano.shared(W_ho, 'W_ho')\n",
    "        b_o = theano.shared(b_o, 'b_o')\n",
    "        # output layer\n",
    "        W_hy = theano.shared(W_hy, 'W_hy')\n",
    "        b_hy = theano.shared(b_hy, 'b_hy')\n",
    "\n",
    "        self.activ1 = T.nnet.sigmoid\n",
    "        self.activ2 = T.tanh\n",
    "        self.activ_out = T.nnet.softmax\n",
    "        \n",
    "        lr = T.scalar()\n",
    "        u = T.matrix()\n",
    "        t = T.matrix()\n",
    "        y = T.matrix()\n",
    "\n",
    "\n",
    "        h0_tm1 = theano.shared(np.ones((1, n_hidden), dtype=theano.config.floatX))\n",
    "        s0_tm1 = theano.shared(np.ones((1, n_hidden), dtype=theano.config.floatX))\n",
    "\n",
    "\n",
    "        #theano.printing.debugprint([u,h0_tm1, s0_tm1, W_ug, W_hg, b_g, \\\n",
    "        #W_ui, W_hi, b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy], print_type=True)\n",
    "        \n",
    "        [h,s], _ = theano.scan(self.recurrent_fn, sequences = u,\n",
    "                           outputs_info = [h0_tm1, s0_tm1],\n",
    "                           non_sequences = [W_ug, W_hg, b_g, W_ui, W_hi,\\\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o,b_hy])\n",
    "        \n",
    "        \n",
    "        \n",
    "        #theano.printing.debugprint([h,W_hy], print_type=True)\n",
    "        out_arg = T.dot(h[-1], W_hy) + b_hy # h is storing all prior predictions\n",
    "                                            # so we only reference the lastest \n",
    "        \n",
    "        y = self.activ_out(out_arg)\n",
    "        \n",
    "        # rank error !\n",
    "        #theano.printing.debugprint([t,y,b_hy,W_hy], print_type=True)\n",
    "        #cost = T.mean(T.nnet.categorical_crossentropy(t,y)) # change positions of args due to log(0) error!\n",
    "        cost = ((t - y)**2).mean(axis=0).sum()\n",
    "\n",
    "        gW_ug, gW_hg, gb_g, gW_ui, gW_hi, gb_i, \\\n",
    "        gW_uf, gW_hf, gb_f, gW_uo, gW_ho, gb_o, gW_hy, gb_hy \\\n",
    "            = T.grad(cost, [W_ug, W_hg, b_g, W_ui, W_hi, b_i, \\\n",
    "            W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy])\n",
    "            \n",
    "        update = [(W_ug, W_ug - lr*gW_ug), \n",
    "                  (W_hg, W_hg - lr*gW_hg ), \n",
    "                  (b_g, b_g - lr*gb_g), \n",
    "                  (W_ui, W_ui - lr*gW_ui),\n",
    "                  (W_hi, W_hi - lr*gW_hi), \n",
    "                  (b_i, b_i - lr*gb_i), \n",
    "                  (W_uf, W_uf - lr*gW_uf), \n",
    "                  (W_hf, W_hf - lr*gW_hf),\n",
    "                  (b_f, b_f - lr*gb_f),\n",
    "                  (W_uo, W_uo - lr*gW_uo), \n",
    "                  (W_ho, W_ho - lr*gW_ho), \n",
    "                  (b_o, b_o - lr*gb_o),\n",
    "                  (W_hy, W_hy - lr*gW_hy), \n",
    "                  (b_hy, b_hy - lr*gb_hy)]\n",
    "        \n",
    "        theano.printing.debugprint([h0_tm1], print_type=True)\n",
    "        self.train_step = theano.function([u, t, lr], cost,\n",
    "            on_unused_input='warn',\n",
    "            updates=update,\n",
    "            allow_input_downcast=True)\n",
    "        \n",
    "        \n",
    "                \n",
    "        self.predict_step = theano.function([u, t], cost,\n",
    "           on_unused_input='warn',\n",
    "           allow_input_downcast=True)\n",
    "        \n",
    "\n",
    "    def recurrent_fn(self, u_t, h_tm1, s_tm1, W_ug, W_hg, b_g, W_ui, W_hi,\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, b_hy):\n",
    "        \n",
    "        g_t = self.activ2(T.dot(u_t, W_ug) + T.dot(h_tm1, W_hg) + b_g)\n",
    "        i_t = self.activ1(T.dot(u_t, W_ui) + T.dot(h_tm1, W_hi) + b_i)\n",
    "        f_t = self.activ1(T.dot(u_t, W_uf) + T.dot(h_tm1, W_hf) + b_f)\n",
    "        o_t = self.activ1(T.dot(u_t, W_uo) + T.dot(h_tm1, W_ho) + b_o)\n",
    "        \n",
    "        s_t = g_t * i_t + s_tm1*f_t\n",
    "        h_t = self.activ2(s_t)*o_t\n",
    "    \n",
    "        #h_t = self.activ(T.dot(h_tm1, W_hh) + T.dot(u_t, W_uh) + b_hh)\n",
    "        return [h_t,s_t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 30088 characters, 58 unique.\n"
     ]
    }
   ],
   "source": [
    "# data I/O\n",
    "data = open('input.txt', 'r').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print 'data has %d characters, %d unique.' % (data_size, vocab_size)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# iterate through data\n",
    "p = 0 \n",
    "# limit 'ch' to 1 character\n",
    "seq_length = len(data) - 1\n",
    "inputs = [char_to_ix[ch] for ch in data[p:p+seq_length]]\n",
    "targets = [char_to_ix[ch]  for ch in data[p+1:p+seq_length+1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorType(float64, matrix)> [@A] <TensorType(float64, matrix)>\n"
     ]
    }
   ],
   "source": [
    "# change dim of output layer, done!\n",
    "nHidden = 20\n",
    "nOutputs = len(chars)\n",
    "nInputs = len(chars)\n",
    "rnn = RNN(nInputs, nHidden, nOutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create labels with one-hot encoding\n",
    "u = []\n",
    "t = []\n",
    "train_mse = []\n",
    "test_mse = []\n",
    "lr = 0.000001\n",
    "count = 0 \n",
    "for i,o in  izip(inputs,targets):   \n",
    "    u = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    u[inputs[i]] = 1 # one-hot encoding\n",
    "    u = u.T\n",
    "    \n",
    "    t = np.zeros((vocab_size,1)) # encode in 1-of-k representation\n",
    "    t[inputs[o]] = 1 # one-hot encoding\n",
    "    t = t.T\n",
    "    \n",
    "    c = rnn.train_step(u, t, lr)\n",
    "    train_mse.append(np.sqrt(c))\n",
    "    \n",
    "    c = rnn.predict_step(u, t)\n",
    "    test_mse.append(np.sqrt(c))\n",
    "    count += 1\n",
    "    \n",
    "    if count == 3:\n",
    "        break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
