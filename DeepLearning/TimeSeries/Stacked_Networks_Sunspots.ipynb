{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Networks Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import cPickle as pickle\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from itertools import izip\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "import theano\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_Strong_Error_Percentage(error_list):\n",
    "    miss = 0\n",
    "    for dist in error_list:\n",
    "        if dist > 30.0:\n",
    "            miss += 1\n",
    "    return miss/ float(len(error_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatter(dataList, histLength=40, predLag=6, trainFrac=0.80):\n",
    "    # Embedding Dimensions, d = 40\n",
    "    # define pointer that starts at histLength and runs to length - predLag\n",
    "    attr = []\n",
    "    y = []\n",
    "    \n",
    "    for iPoint in range(histLength, len(dataList) - predLag):\n",
    "        # flatten history before iPoint and calculate change in closing price between iPoint and iPoint + predLag\n",
    "        attrLine = []\n",
    "        \n",
    "        for i in range(iPoint-histLength, iPoint):\n",
    "            # flattens histLength many rows into a single row\n",
    "            attrLine += dataList[i]\n",
    "            \n",
    "        # attrLine = [temp + dataList[i] for i in range(iPoint-histLength, iPoint)]\n",
    "        attr.append(attrLine)\n",
    "        currClse = dataList[iPoint][0]          # only get sunspots\n",
    "        futClse = dataList[iPoint + predLag][0] # only get sunspots\n",
    "        yVal = futClse - currClse\n",
    "        y.append(yVal)  #difference in closing prices\n",
    "        \n",
    "    #calculate index for start of training set\n",
    "    #trainStart = int(trainFrac * len(attr))\n",
    "    #xTr = attr[:trainStart]; xTe = attr[trainStart:]; yTr = y[:trainStart]; yTe = y[trainStart:]\n",
    "    #xTr = np.array(attr)\n",
    "    #yTr = np.array(y)\n",
    "    #attr = MaxAbsScaler().fit_transform(attr)\n",
    "    return  attr, y    #take raw pricing data, return numpy array of attributes and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./SN_m_tot_V2.0.csv\",sep = \";\", header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_past_datas_sunspots, y_true_future_sunspot = formatter(df.values[:,3:4].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3157, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_past_datas_sunspots).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3157,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_true_future_sunspot).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(x_past_datas_sunspots,\n",
    "                                                y_true_future_sunspot,\n",
    "                                                test_size = 0.15,\n",
    "                                               random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# StandardScaler centers data around 0\n",
    "x_ss = StandardScaler().fit_transform(xTrain)\n",
    "# MaxAbsScaler scales data between [-1,1]\n",
    "xtrain_mas = MaxAbsScaler().fit_transform(x_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest_ss = StandardScaler().fit_transform(xTest)\n",
    "xtest_mas = MaxAbsScaler().fit_transform(xtest_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero mean centred and scaled data [-1,1]\n",
      "7.49517653755e-18\n",
      "1.0\n",
      "-0.423525344255\n"
     ]
    }
   ],
   "source": [
    "print \"zero mean centred and scaled data [-1,1]\"\n",
    "print np.mean(xtest_mas)\n",
    "print  np.max(xtest_mas)\n",
    "print np.min(xtest_mas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = np.array(xtrain_mas, dtype = theano.config.floatX)\n",
    "ytrain = np.array(yTrain, dtype = theano.config.floatX)\n",
    "Xtest = np.array(xtest_mas, dtype = theano.config.floatX)\n",
    "Ytest = np.array(yTest, dtype = theano.config.floatX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack FC and SLTM Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stacked_Network(object):\n",
    "\n",
    "    def __init__(self, nin, n_hidden, nout, wh_dim, wh2_dim, wh3_dim):\n",
    "        rng = np.random.RandomState(1234)\n",
    "        # cell input\n",
    "        W_ug = np.asarray(rng.normal(size=(nin, n_hidden), scale= .01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        W_hg = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale=.01, loc = 0.0), dtype = theano.config.floatX)\n",
    "        b_g = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # input gate equation\n",
    "        W_ui = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hi = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_i = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # forget gate equations\n",
    "        W_uf = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_hf = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_f = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # cell output gate equations\n",
    "        W_uo = np.asarray(rng.normal(size=(nin, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        W_ho = np.asarray(rng.normal(size=(n_hidden, n_hidden), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_o = np.zeros((n_hidden,), dtype=theano.config.floatX)\n",
    "        # output layer\n",
    "        W_hy = np.asarray(rng.normal(size=(n_hidden, nout), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_hy = np.zeros((nout,), dtype=theano.config.floatX)\n",
    "\n",
    "        # cell input\n",
    "        W_ug = theano.shared(W_ug, 'W_ug')\n",
    "        W_hg = theano.shared(W_hg, 'W_hg')\n",
    "        b_g = theano.shared(b_g, 'b_g')\n",
    "        # input gate equation\n",
    "        W_ui = theano.shared(W_ui, 'W_ui')\n",
    "        W_hi = theano.shared(W_hi, 'W_hi')\n",
    "        b_i = theano.shared(b_i, 'b_i')\n",
    "        # forget gate equations\n",
    "        W_uf = theano.shared(W_uf, 'W_uf')\n",
    "        W_hf = theano.shared(W_hf, 'W_hf')\n",
    "        b_f = theano.shared(b_f, 'b_f')\n",
    "        # cell output gate equations\n",
    "        W_uo = theano.shared(W_uo, 'W_uo')\n",
    "        W_ho = theano.shared(W_ho, 'W_ho')\n",
    "        b_o = theano.shared(b_o, 'b_o')\n",
    "        # output layer\n",
    "        W_hy = theano.shared(W_hy, 'W_hy')\n",
    "        b_hy = theano.shared(b_hy, 'b_hy')\n",
    "\n",
    "        \n",
    "        def floatX(X):\n",
    "            return np.asarray(X, dtype=theano.config.floatX)\n",
    "         \n",
    "        b_h = np.asarray(rng.normal(size=((wh_dim[1],)), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_h = theano.shared(b_h, 'b_h')\n",
    "        \n",
    "    \n",
    "        b_h2 = np.asarray(rng.normal(size=((wh2_dim[1],)), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_h2 = theano.shared(b_h2, 'b_h2')\n",
    "        \n",
    "        b_h3 = np.asarray(rng.normal(size=((wh3_dim[1],)), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        b_h3 = theano.shared(b_h3, 'b_h3')\n",
    "        \n",
    "        (h, w) = wh_dim\n",
    "        w_h = np.asarray(rng.normal(size=((h, w)), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        w_h = theano.shared(w_h, 'w_h')\n",
    "        \n",
    "        (h, w) = wh2_dim\n",
    "        w_h2 = np.asarray(rng.normal(size=((h, w)), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        w_h2 = theano.shared(w_h2, 'w_h2')\n",
    "        \n",
    "        (h, w) = wh3_dim\n",
    "        w_h3 = np.asarray(rng.normal(size=((h, w)), scale =.01, loc=0.0), dtype = theano.config.floatX)\n",
    "        w_h3 = theano.shared(w_h3, 'w_h2')\n",
    "\n",
    "        self.activ1 = T.nnet.sigmoid\n",
    "        self.activ2 = T.tanh\n",
    "        \n",
    "        lr = T.scalar()\n",
    "        u = T.matrix()\n",
    "        t = T.scalar()\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        def rectify(X):\n",
    "            #return T.maximum(X, 0.)\n",
    "            return T.maximum(X, 0.01*(T.exp(X)-1))  #exponential linear rectifer\n",
    "            #return T.maximum(X, 0.01*X)  #leaky rectifier\n",
    "        \n",
    "        def model(X, w_h,w_h2,w_h3, b_h, b_h2, b_h3):\n",
    "            h = rectify(T.dot(X, w_h) + b_h)\n",
    "\n",
    "            h2 = rectify(T.dot(h, w_h2) + b_h2)\n",
    "\n",
    "            h3 = rectify(T.dot(h2, w_h3) + b_h3)\n",
    "\n",
    "            return h3\n",
    "        \n",
    "        \n",
    "        \n",
    "        def adaGrad(cost, params, eta=0.1, epsilon=1e-6):\n",
    "            grads = T.grad(cost=cost, wrt=params)\n",
    "            updates = []\n",
    "            for p, g in zip(params, grads):\n",
    "                sumGSq = theano.shared(p.get_value() * 0.)\n",
    "                sumGSq_new = sumGSq + g ** 2\n",
    "                gradient_scaling = T.sqrt(sumGSq_new + epsilon)\n",
    "                g = g / gradient_scaling\n",
    "                updates.append((sumGSq, sumGSq_new))\n",
    "                updates.append((p, p - eta * g))\n",
    "            return updates\n",
    "        \n",
    "        h0_tm1 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "        s0_tm1 = theano.shared(np.zeros(n_hidden, dtype=theano.config.floatX))\n",
    "        \n",
    "        u1 = model(u, \n",
    "                  w_h,\n",
    "                  w_h2,\n",
    "                  w_h3,\n",
    "                  b_h, \n",
    "                  b_h2,\n",
    "                  b_h3)\n",
    "\n",
    "        #theano.printing.debugprint([h0_tm1, u, W_hh, W_uh, W_hy, b_hh, b_hy], print_type=True)\n",
    "        [h, s], _ = theano.scan(self.recurrent_fn, sequences = u1,\n",
    "                           outputs_info = [h0_tm1, s0_tm1],\n",
    "                           non_sequences = [W_ug, W_hg, b_g, W_ui, W_hi,\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy])\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        # Output Layer\n",
    "        y = T.dot(h[-1], W_hy) + b_hy\n",
    "        cost = ((t - y)**2).mean(axis=0).sum()\n",
    "\n",
    "        gw_h,gw_h2,gw_h3,gb_h, gb_h2,gb_h3,\\\n",
    "        gW_ug, gW_hg, gb_g, gW_ui, gW_hi, gb_i, \\\n",
    "        gW_uf, gW_hf, gb_f, gW_uo, gW_ho, gb_o, gW_hy, gb_hy \\\n",
    "            = T.grad(cost, [ w_h,w_h2,w_h3, b_h, b_h2,b_h3,\\\n",
    "                             W_ug, W_hg, b_g, W_ui, W_hi, b_i, \\\n",
    "                             W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy, b_hy])\n",
    "                    \n",
    "                 # LSTM weights \n",
    "        update = [(W_ug, W_ug - lr*gW_ug), \n",
    "                  (W_hg, W_hg - lr*gW_hg ), \n",
    "                  (b_g, b_g - lr*gb_g), \n",
    "                  (W_ui, W_ui - lr*gW_ui),\n",
    "                  (W_hi, W_hi - lr*gW_hi), \n",
    "                  (b_i, b_i - lr*gb_i), \n",
    "                  (W_uf, W_uf - lr*gW_uf), \n",
    "                  (W_hf, W_hf - lr*gW_hf),\n",
    "                  (b_f, b_f - lr*gb_f),\n",
    "                  (W_uo, W_uo - lr*gW_uo), \n",
    "                  (W_ho, W_ho - lr*gW_ho), \n",
    "                  (b_o, b_o - lr*gb_o),\n",
    "                  (W_hy, W_hy - lr*gW_hy), \n",
    "                  (b_hy, b_hy - lr*gb_hy),\n",
    "                  # FC weights\n",
    "                  (w_h, w_h - lr * gw_h),\n",
    "                  (w_h2, w_h2 - lr* gw_h2),\n",
    "                  (w_h3, w_h3 - lr* gw_h3),\n",
    "                  (b_h,b_h - lr*gb_h ),\n",
    "                  (b_h2, b_h2 - lr* gb_h2),\n",
    "                  (b_h3,b_h3 - lr*gb_h3 )]\n",
    "        \n",
    "        #theano.printing.debugprint([h0_tm1], print_type=True)\n",
    "        self.train_step = theano.function([u, t, lr], cost,\n",
    "            on_unused_input='warn',\n",
    "            updates=update,\n",
    "            allow_input_downcast=True)\n",
    "        \n",
    "        \n",
    "                \n",
    "        self.predict_step = theano.function([u, t], cost,\n",
    "           on_unused_input='warn',\n",
    "           allow_input_downcast=True)\n",
    "    \n",
    "    \n",
    "    def recurrent_fn(self, u_t, h_tm1, s_tm1, W_ug, W_hg, b_g, W_ui, W_hi,\n",
    "                                            b_i, W_uf, W_hf, b_f, W_uo, W_ho, b_o, W_hy,b_hy):\n",
    "        \n",
    "        \n",
    "        g_t = self.activ2(T.dot(u_t, W_ug) + T.dot(h_tm1, W_hg) + b_g)\n",
    "        i_t = self.activ1(T.dot(u_t, W_ui) + T.dot(h_tm1, W_hi) + b_i)\n",
    "        f_t = self.activ1(T.dot(u_t, W_uf) + T.dot(h_tm1, W_hf) + b_f)\n",
    "        o_t = self.activ1(T.dot(u_t, W_uo) + T.dot(h_tm1, W_ho) + b_o)\n",
    "        s_t = g_t * i_t + s_tm1*f_t\n",
    "        h_t = self.activ2(s_t)*o_t\n",
    "        \n",
    "        #h_t = self.activ2(T.dot(h_tm1, W_hh) + T.dot(u_t, W_uh) + b_hh)\n",
    "        return [h_t, s_t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LSTM Dimensions\n",
    "nInputs = 100\n",
    "nHidden = 20\n",
    "nOutputs = 1\n",
    "# FC Network Dimensions\n",
    "wh_dim = (40, 100)\n",
    "wh2_dim = (100, 500)\n",
    "wh3_dim = (500, 100)\n",
    "lr = 0.001\n",
    "e = 1.0\n",
    "\n",
    "\n",
    "rnn = Stacked_Network(nInputs, \n",
    "                      nHidden, \n",
    "                      nOutputs,\n",
    "                      wh_dim,\n",
    "                     wh2_dim,\n",
    "                     wh3_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train iteration 0: 55.7000114639\n",
      "train iteration 200: 26.7819413457\n",
      "train iteration 400: 17.9593297174\n",
      "train iteration 600: 8.91778693751\n",
      "train iteration 800: 21.4990461026\n",
      "train iteration 1000: 24.2213266143\n",
      "train iteration 1200: 44.5800787993\n",
      "train iteration 1400: 16.5213591366\n",
      "train iteration 1600: 1.53061495654\n",
      "train iteration 1800: 15.9178942207\n",
      "train iteration 2000: 36.2789606436\n",
      "train iteration 2200: 15.1863230194\n",
      "train iteration 2400: 12.2493915309\n",
      "train iteration 2600: 23.9119233509\n"
     ]
    }
   ],
   "source": [
    "train_mse = []\n",
    "train_error_smooth = []\n",
    "\n",
    "train_length = len(Xtrain)\n",
    "test_length = len(Xtest)\n",
    "\n",
    "# train weights\n",
    "for j in xrange(train_length):\n",
    "    u = Xtrain[j].reshape((1,40))\n",
    "    t = ytrain[j]\n",
    "\n",
    "    c = rnn.train_step(u, t, lr)\n",
    "    if j%200==0: print \"train iteration {0}: {1}\".format(j, np.sqrt(c))\n",
    "    e = 0.1*np.sqrt(c) + 0.9*e\n",
    "    # for taining modification, do not smooth the error\n",
    "    train_mse.append(np.sqrt(c))\n",
    "    train_error_smooth.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test iteration 0: 87.7121614986\n",
      "test iteration 200: 1.88783826083\n",
      "test iteration 400: 27.1878382554\n"
     ]
    }
   ],
   "source": [
    "test_mse = []\n",
    "test_error_smooth = []\n",
    "\n",
    "# make predictions                       \n",
    "for k in xrange(test_length):\n",
    "    u = Xtest[k].reshape((1,40))\n",
    "    t = Ytest[k]\n",
    "\n",
    "    c = rnn.predict_step(u, t)\n",
    "    if k%200==0: print \"test iteration {0}: {1}\".format(k, np.sqrt(c))\n",
    "    e = 0.1*np.sqrt(c) + 0.9*e\n",
    "    # for taining modification, do not smooth the error\n",
    "    test_mse.append(np.sqrt(c))\n",
    "    test_error_smooth.append(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3670886075949367"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Strong_Error_Percentage(test_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
